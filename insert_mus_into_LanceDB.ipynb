{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34e3b3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8df3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import bioacoustics_model_zoo as bmz\n",
    "import csv\n",
    "import lancedb\n",
    "import pyarrow as pa\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c50afdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What Code does: Perch can only generate embeddings for audio files greater than 5 seconds. Therefore, loop any short audio files to make it atleast 5 seconds\n",
    "def pad_short_clip(audio_path):\n",
    "    target_duration_sec = 5\n",
    "    samplerate=sf.info(audio_path).samplerate\n",
    "    target_len = samplerate * target_duration_sec\n",
    "    y, sr = librosa.load(audio_path, sr=samplerate)\n",
    "    #pad if less than 5 seconds\n",
    "    if len(y) < target_len:\n",
    "        reps = int(np.ceil(target_len / len(y)))\n",
    "        y = np.tile(y, reps)[:target_len]\n",
    "    return np.asarray(y, dtype=np.float32), sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f6f2eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(audio_path):\n",
    "    info = sf.info(audio_path)\n",
    "    duration = info.frames / info.samplerate #faster than using librosa to load length\n",
    "    if (duration < 5):\n",
    "        formatted_wav, sample_rate = pad_short_clip(audio_path)\n",
    "        #creates a new wav file of 5 seconds long to generate embedding and then immediately deletes it\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as tmp:\n",
    "            # Write the array to the temp .wav file\n",
    "            sf.write(tmp.name, formatted_wav, sample_rate)\n",
    "            # Use the file path for embedding\n",
    "            embedding = model.embed(tmp.name)\n",
    "    # if >=5 seconds then embed directly\n",
    "    else:\n",
    "        embedding = model.embed(audio_path)\n",
    "    return embedding, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25376454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE To Muha: Change the file path to your CSV file that contains liked sound information & the root directory to your data\n",
    "csv_file_path = \"/home/s.kamboj.400/unzipped-music/mount/Liked Sounds/Location A Sand Forrest/Metadat -  Sandforest.csv\"\n",
    "#all wav files must be under this root directory. The structure of the directory beyond that does not matter.\n",
    "root_dir = \"/home/s.kamboj.400/unzipped-music/mount/\"\n",
    "\n",
    "#order: \n",
    "#   1. parse the csv of liked & generate a hashmap where key is the filename & value is the entire dicitonary that would be the entry to lancedb\n",
    "#   2. go through ALL wav files in directory & see if its filename matches the filename of the key in the hashmp from step 1. if so, then, insert it as a new column in the value dictionary.\n",
    "#        -> save path to all wav files in array\n",
    "#   3. once you have gone through ALL wav files in the direcotry & if any do not have a filepath associated with them, then remove them from the hashmap entirely\n",
    "# === Step 1: Parse the CSV & build the hashmap ===\n",
    "filename_to_metadata = {}\n",
    "\n",
    "with open(csv_file_path, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=';')\n",
    "    for row in reader:\n",
    "        filename = row[\"FileName\"]\n",
    "        filename_to_metadata[filename] = dict(row)\n",
    "    # After parsing your CSV\n",
    "\n",
    "#get all columns so that you can create empty frames later on\n",
    "fieldnames = list(next(iter(filename_to_metadata.values())).keys())\n",
    "fieldnames.append(\"FilePath\") \n",
    "#print(fieldnames)\n",
    "\n",
    "\n",
    "# === Step 2: Walk through all .wav files and insert filepath ===\n",
    "matched_filenames = set()\n",
    "all_audio_files = []\n",
    "\n",
    "countInvalid=0\n",
    "countLessThanFive=0\n",
    "\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "    for name in filenames:\n",
    "        if name.endswith(\".wav\"):\n",
    "            full_path = os.path.join(dirpath, name)\n",
    "            #makes sure file is not corrupted\n",
    "            try:\n",
    "                sf.info(full_path)\n",
    "            except (RuntimeError, sf.LibsndfileError):\n",
    "                continue\n",
    "\n",
    "            # duration_seconds = librosa.get_duration(path=full_path)\n",
    "            # if (duration_seconds<5):\n",
    "            #     countLessThanFive+=1\n",
    "            if name in filename_to_metadata:\n",
    "                # Case 1: metadata already exists for liked sounds — just add path\n",
    "                filename_to_metadata[name][\"FilePath\"] = full_path\n",
    "                matched_filenames.add(name)\n",
    "            elif \"Liked Sounds\" in os.path.normpath(dirpath).split(os.sep):\n",
    "                # Case 2: in \"Liked Sounds\" folder but not in the metadata csv filename — add blank metadata (this is because there are some files in liked sounds that are not listed in the metadata csv)\n",
    "                    # we do still need to give it the metadata frame \n",
    "                new_entry = {field: \"\" for field in fieldnames}\n",
    "                new_entry[\"FileName\"] = name\n",
    "                new_entry[\"FilePath\"] = full_path\n",
    "                filename_to_metadata[name] = new_entry\n",
    "                #ensures this \n",
    "                matched_filenames.add(name)\n",
    "            else:\n",
    "                #not a liked song at all. then, store its path so that you can generate and insert embeddings into lancedb. \n",
    "                # use the other audio paths in the frame to generate embeddings for queries\n",
    "                all_audio_files.append(str(full_path))\n",
    "            \n",
    "                # print(f\"This audio file {full_path} is not valid (probably corrupted), so nothing is happening\")\n",
    "\n",
    "# === Step 3: Remove unmatched entries ===\n",
    "# This will only keep entries that were matched with a .wav file, basically deleted any \"liked files\" whose audio does not actually exist\n",
    "filename_to_metadata = {\n",
    "    fname: metadata\n",
    "    for fname, metadata in filename_to_metadata.items()\n",
    "    if fname in matched_filenames\n",
    "}\n",
    "# print(\"len of all audio files is \", len(all_audio_files))\n",
    "# print(\"len of all metadata is \", len(filename_to_metadata))\n",
    "# print(f\"There are {countInvalid} invalid files\")\n",
    "# print(f\"There are {countLessThanFive} audio recordings less than 5 seconds\") #3464 audio recordings less than 5 seconds\n",
    "#no longer make it a key-value pair. now metadata_list is a list of dictionaries of liked sounds that are ready to be inserted into lancedb\n",
    "metadata_list = list(filename_to_metadata.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573acaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to LanceDB and make schema to save the embeddings\n",
    "uri = \"database/music_db.lance\"\n",
    "db = lancedb.connect(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE To Muha: This code deletes the table if it exists. I kept this code there for testing purposes. You should uncomment it out the first time you run the code, but once you generate the database, you don't need to run this code again.\n",
    "# if \"music_embeddings\" in db.table_names():\n",
    "#     print(\"Table exists. If you run the next couple code blocks again, then you will get duplicate embeddings. Uncomment the next line to delete the table.\")\n",
    "#     #db.drop_table(\"music_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE To Muha: Uncomment the next lines of code if regenerating the database, or generating for the first time.\n",
    "# schema = pa.schema([\n",
    "#     pa.field(\"FileName\", pa.string()),\n",
    "#     pa.field(\"Format\", pa.string()),\n",
    "#     pa.field(\"Note\", pa.string()),\n",
    "#     pa.field(\"Take\", pa.string()),\n",
    "#     pa.field(\"Scene\", pa.string()),\n",
    "#     pa.field(\"Project\", pa.string()), \n",
    "#     pa.field(\"Category\", pa.string()), \n",
    "#     pa.field(\"Library\", pa.string()), \n",
    "#     pa.field(\"Tape\", pa.string()), \n",
    "#     pa.field(\"Channels\", pa.string()), \n",
    "#     pa.field(\"Originator\", pa.string()), \n",
    "#     pa.field(\"Reference\", pa.string()), \n",
    "#     pa.field(\"Description\", pa.string()),\n",
    "#     pa.field(\"Duration\", pa.string()), #REMEMBER! duration should store the start time to end time of the embedding as a string so be sure to change that. this is because the embedding generates an array of 5 second chunks\n",
    "#     pa.field(\"FilePath\", pa.string()),  \n",
    "#     pa.field(\"Looped\", pa.bool_()),\n",
    "#     pa.field(\"vector_embedding\", pa.list_(pa.float32(), list_size=1280)),\n",
    "# ])\n",
    "# table = db.create_table(\"music_embeddings\", schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "207138ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/siyakamboj/Downloads/LanceDB_NatGeo/.venv/lib/python3.10/site-packages/tensorflow_hub/__init__.py:61: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  from pkg_resources import parse_version\n",
      "/Users/siyakamboj/Downloads/LanceDB_NatGeo/.venv/lib/python3.10/site-packages/opensoundscape/ml/cnn.py:599: UserWarning: \n",
      "                    This architecture is not listed in opensoundscape.ml.cnn_architectures.ARCH_DICT.\n",
      "                    It will not be available for loading after saving the model with .save() (unless using pickle=True). \n",
      "                    To make it re-loadable, define a function that generates the architecture from arguments: (n_classes, n_channels) \n",
      "                    then use opensoundscape.ml.cnn_architectures.register_architecture() to register the generating function.\n",
      "\n",
      "                    The function can also set the returned object's .constructor_name to the registered string key in ARCH_DICT\n",
      "                    to avoid this warning and ensure it is reloaded correctly by opensoundscape.ml.load_model().\n",
      "\n",
      "                    See opensoundscape.ml.cnn_architectures module for examples of constructor functions\n",
      "                    \n",
      "  warnings.warn(\n",
      "/Users/siyakamboj/Downloads/LanceDB_NatGeo/.venv/lib/python3.10/site-packages/opensoundscape/ml/cnn.py:623: UserWarning: Failed to detect expected # input channels of this architecture.Make sure your architecture expects the number of channels equal to `channels` argument 1). Pytorch architectures generally expect 3 channels by default.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# # Generate vector embeddings of all audios using perch embeddings and insert into lancedb\n",
    "model=bmz.Perch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### STEP 2: insert vector embeddings of all sounds into lancedb #######\n",
    "#Insert data into lancedb\n",
    "count=0\n",
    "records_to_insert=[]\n",
    "batch_size_to_insert=100\n",
    "# countOfLessThan5=0\n",
    "for curr_wav_file in all_audio_files:\n",
    "    #return embedding & duration so you can determine if looped or not\n",
    "    embedding, duration= generate_embedding(curr_wav_file)\n",
    "\n",
    "    #loop through all chunks of 5 second recordings for current wav file and insert into lancedb\n",
    "    for i in range(embedding.shape[0]):\n",
    "        embedding = np.array(embedding) # forces len of embedding to be 1280 by not letting embedding change dimensions\n",
    "        start_sec = i * 5\n",
    "        end_sec = (i + 1) * 5\n",
    "        duration_str = f\"{start_sec}-{end_sec}\"\n",
    "        metadata = {\n",
    "            \"FileName\": os.path.basename(curr_wav_file),\n",
    "            \"Format\": \"\",         \n",
    "            \"Note\": \"\",\n",
    "            \"Take\": \"\",\n",
    "            \"Scene\": \"\",\n",
    "            \"Project\": \"\",\n",
    "            \"Category\": \"\",\n",
    "            \"Library\": \"\",\n",
    "            \"Tape\": \"\",\n",
    "            \"Channels\": \"\",\n",
    "            \"Originator\": \"\",\n",
    "            \"Reference\": \"\",\n",
    "            \"Description\": \"\",\n",
    "            \"Duration\": duration_str,\n",
    "            \"FilePath\": curr_wav_file,\n",
    "            \"Looped\": duration < 5,\n",
    "            \"vector_embedding\": embedding[i].tolist(),  \n",
    "        }\n",
    "        records_to_insert.append(metadata)\n",
    "        #fast batching for lancedb insertion & memory safe\n",
    "        if len(records_to_insert) >= batch_size_to_insert:\n",
    "            table.add(records_to_insert)\n",
    "            records_to_insert.clear()\n",
    "    # count+=1\n",
    "    # if (count>=5000):\n",
    "    #     break\n",
    "#insert any remaining records\n",
    "if records_to_insert:\n",
    "    table.add(records_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b53eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check stuff was inserted\n",
    "df = table.to_pandas()\n",
    "print(df.head())  # Show first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6474d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP 3 : Generate vector embeddings of liked sounds and generate similarity search of liked sounds #######\n",
    "#loop through liked sounds & generate vector embeddings\n",
    "from IPython.display import Audio, display\n",
    "count=0\n",
    "for currLikedDict in metadata_list:\n",
    "    audio_path= currLikedDict[\"FilePath\"]\n",
    "    embedding, _= generate_embedding(audio_path)\n",
    "    for i in range(embedding.shape[0]):\n",
    "        embedding = np.array(embedding)\n",
    "        query_vector = embedding[i].tolist()\n",
    "        #search lancedb with those vector embeddings\n",
    "        results = table.search(query_vector).limit(1).to_pandas()\n",
    "        print(\"The most similar to \", audio_path, \" chunk #\", (i+1), \" is\", results[\"FilePath\"].tolist()[0])\n",
    "        print(\"Liked audio:\")\n",
    "        display(Audio(audio_path))\n",
    "        matched_path = results[\"FilePath\"].tolist()[0]\n",
    "        matched_duration = results[\"Duration\"].tolist()[0]\n",
    "        # Parse \"start-end\" from Duration field\n",
    "        start_sec, end_sec = map(int, matched_duration.split('-'))\n",
    "        duration = end_sec - start_sec\n",
    "\n",
    "        # Load just the 5-second chunk (efficient)\n",
    "        y, sr = librosa.load(matched_path, sr=None, offset=start_sec, duration=duration)\n",
    "\n",
    "        # Display the audio player\n",
    "        print(\"Most similar 5-second chunk from time :\", matched_duration)\n",
    "        display(Audio(y, rate=sr))\n",
    "\n",
    "    # count+=1\n",
    "    # if (count>5):\n",
    "    #     break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv-venv-music",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
