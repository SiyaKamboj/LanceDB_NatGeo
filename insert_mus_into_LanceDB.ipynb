{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e3b3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8df3b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import bioacoustics_model_zoo as bmz\n",
    "import csv\n",
    "import lancedb\n",
    "import pyarrow as pa\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c50afdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perch can only generate embeddings for audio files greater than 5 seconds. Therefore, loop any short audio files to make it atleast 5 seconds\n",
    "def pad_short_clip(audio_path):\n",
    "    target_duration_sec = 5\n",
    "    samplerate=sf.info(audio_path).samplerate\n",
    "    target_len = samplerate * target_duration_sec\n",
    "    y, sr = librosa.load(audio_path, sr=samplerate)\n",
    "    #pad if less than 5 seconds\n",
    "    if len(y) < target_len:\n",
    "        reps = int(np.ceil(target_len / len(y)))\n",
    "        y = np.tile(y, reps)[:target_len]\n",
    "    return np.asarray(y, dtype=np.float32), sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f6f2eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(audio_path):\n",
    "    info = sf.info(audio_path)\n",
    "    duration = info.frames / info.samplerate #faster than using librosa to load length\n",
    "    if (duration < 5):\n",
    "        formatted_wav, sample_rate = pad_short_clip(audio_path)\n",
    "        #creates a new wav file of 5 seconds long to generate embedding and then immediately deletes it\n",
    "        with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=True) as tmp:\n",
    "            # Write the array to the temp .wav file\n",
    "            sf.write(tmp.name, formatted_wav, sample_rate)\n",
    "            # Use the file path for embedding\n",
    "            embedding = model.embed(tmp.name)\n",
    "    # if >=5 seconds then embed directly\n",
    "    else:\n",
    "        embedding = model.embed(audio_path)\n",
    "    return embedding, duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25376454",
   "metadata": {},
   "outputs": [],
   "source": [
    "#order: \n",
    "#   1. parse the csv of liked & generate a hashmap where key is the filename & value is the entire dicitonary that would be the entry to lancedb\n",
    "#   2. go through ALL wav files in directory & see if its filename matches the filename of the key in the hashmp from step 1. if so, then, insert it as a new column in the value dictionary.\n",
    "#        -> save path to all wav files in array\n",
    "#   3. once you have gone through ALL wav files in the direcotry & if any do not have a filepath associated with them, then remove them from the hashmap entirely\n",
    "\n",
    "# === Step 1: Parse the CSV & build the hashmap ===\n",
    "#NOTE: Change the file path to your CSV file and root directory\n",
    "csv_file_path = \"/home/s.kamboj.400/unzipped-music/mount/Liked Sounds/Location A Sand Forrest/Metadat -  Sandforest.csv\"\n",
    "#all wav files must be under this root directory. The structure of the directory beyond that does not matter.\n",
    "root_dir = \"/home/s.kamboj.400/unzipped-music/mount/\"\n",
    "filename_to_metadata = {}\n",
    "\n",
    "with open(csv_file_path, newline='', encoding='utf-8') as csvfile:\n",
    "    reader = csv.DictReader(csvfile, delimiter=';')\n",
    "    for row in reader:\n",
    "        filename = row[\"FileName\"]\n",
    "        filename_to_metadata[filename] = dict(row)\n",
    "    # After parsing your CSV\n",
    "\n",
    "#get all columns so that you can create empty frames later on\n",
    "fieldnames = list(next(iter(filename_to_metadata.values())).keys())\n",
    "fieldnames.append(\"FilePath\") \n",
    "#print(fieldnames)\n",
    "\n",
    "\n",
    "# === Step 2: Walk through all .wav files and insert filepath ===\n",
    "matched_filenames = set()\n",
    "all_audio_files = []\n",
    "\n",
    "countInvalid=0\n",
    "countLessThanFive=0\n",
    "\n",
    "for dirpath, _, filenames in os.walk(root_dir):\n",
    "    for name in filenames:\n",
    "        if name.endswith(\".wav\"):\n",
    "            full_path = os.path.join(dirpath, name)\n",
    "            #makes sure file is not corrupted\n",
    "            try:\n",
    "                sf.info(full_path)\n",
    "            except (RuntimeError, sf.LibsndfileError):\n",
    "                continue\n",
    "\n",
    "            # duration_seconds = librosa.get_duration(path=full_path)\n",
    "            # if (duration_seconds<5):\n",
    "            #     countLessThanFive+=1\n",
    "            if name in filename_to_metadata:\n",
    "                # Case 1: metadata already exists for liked sounds — just add path\n",
    "                filename_to_metadata[name][\"FilePath\"] = full_path\n",
    "                matched_filenames.add(name)\n",
    "            elif \"Liked Sounds\" in os.path.normpath(dirpath).split(os.sep):\n",
    "                # Case 2: in \"Liked Sounds\" folder but not in the metadata csv filename — add blank metadata (this is because there are some files in liked sounds that are not listed in the metadata csv)\n",
    "                    # we do still need to give it the metadata frame \n",
    "                new_entry = {field: \"\" for field in fieldnames}\n",
    "                new_entry[\"FileName\"] = name\n",
    "                new_entry[\"FilePath\"] = full_path\n",
    "                filename_to_metadata[name] = new_entry\n",
    "                #ensures this \n",
    "                matched_filenames.add(name)\n",
    "            else:\n",
    "                #not a liked song at all. then, store its path so that you can generate and insert embeddings into lancedb. \n",
    "                # use the other audio paths in the frame to generate embeddings for queries\n",
    "                all_audio_files.append(str(full_path))\n",
    "            \n",
    "                # print(f\"This audio file {full_path} is not valid (probably corrupted), so nothing is happening\")\n",
    "\n",
    "# === Step 3: Remove unmatched entries ===\n",
    "# This will only keep entries that were matched with a .wav file, basically deleted any \"liked files\" whose audio does not actually exist\n",
    "filename_to_metadata = {\n",
    "    fname: metadata\n",
    "    for fname, metadata in filename_to_metadata.items()\n",
    "    if fname in matched_filenames\n",
    "}\n",
    "# print(\"len of all audio files is \", len(all_audio_files))\n",
    "# print(\"len of all metadata is \", len(filename_to_metadata))\n",
    "# print(f\"There are {countInvalid} invalid files\")\n",
    "# print(f\"There are {countLessThanFive} audio recordings less than 5 seconds\") #3464 audio recordings less than 5 seconds\n",
    "#no longer make it a key-value pair. now metadata_list is a list of dictionaries of liked sounds that are ready to be inserted into lancedb\n",
    "metadata_list = list(filename_to_metadata.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573acaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Connect to LanceDB and make schema to save the embeddings\n",
    "uri = \"database/music_db.lance\"\n",
    "db = lancedb.connect(uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1be0b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOTE: This code deletes the table if it exists. I kept this code there for testing purposes, but once you generate the database, do not run this code again.\n",
    "# if \"music_embeddings\" in db.table_names():\n",
    "#     print(\"Table exists. If you run the next couple code blocks again, then you will get duplicate embeddings. Uncomment the next line to delete the table.\")\n",
    "#     #db.drop_table(\"music_embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a1af28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema = pa.schema([\n",
    "#     pa.field(\"FileName\", pa.string()),\n",
    "#     pa.field(\"Format\", pa.string()),\n",
    "#     pa.field(\"Note\", pa.string()),\n",
    "#     pa.field(\"Take\", pa.string()),\n",
    "#     pa.field(\"Scene\", pa.string()),\n",
    "#     pa.field(\"Project\", pa.string()), \n",
    "#     pa.field(\"Category\", pa.string()), \n",
    "#     pa.field(\"Library\", pa.string()), \n",
    "#     pa.field(\"Tape\", pa.string()), \n",
    "#     pa.field(\"Channels\", pa.string()), \n",
    "#     pa.field(\"Originator\", pa.string()), \n",
    "#     pa.field(\"Reference\", pa.string()), \n",
    "#     pa.field(\"Description\", pa.string()),\n",
    "#     pa.field(\"Duration\", pa.string()), #REMEMBER! duration should store the start time to end time of the embedding as a string so be sure to change that. this is because the embedding generates an array of 5 second chunks\n",
    "#     pa.field(\"FilePath\", pa.string()),  \n",
    "#     pa.field(\"Looped\", pa.bool_()),\n",
    "#     pa.field(\"vector_embedding\", pa.list_(pa.float32(), list_size=1280)),\n",
    "# ])\n",
    "# table = db.create_table(\"music_embeddings\", schema=schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207138ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Generate vector embeddings of all audios using perch embeddings and insert into lancedb\n",
    "model=bmz.Perch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89e38aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### STEP 2: insert vector embeddings of all sounds into lancedb #######\n",
    "#Insert data into lancedb\n",
    "count=0\n",
    "records_to_insert=[]\n",
    "batch_size_to_insert=100\n",
    "# countOfLessThan5=0\n",
    "for curr_wav_file in all_audio_files:\n",
    "    #return embedding & duration so you can determine if looped or not\n",
    "    embedding, duration= generate_embedding(curr_wav_file)\n",
    "\n",
    "    #loop through all chunks of 5 second recordings for current wav file and insert into lancedb\n",
    "    for i in range(embedding.shape[0]):\n",
    "        embedding = np.array(embedding) # forces len of embedding to be 1280 by not letting embedding change dimensions\n",
    "        start_sec = i * 5\n",
    "        end_sec = (i + 1) * 5\n",
    "        duration_str = f\"{start_sec}-{end_sec}\"\n",
    "        metadata = {\n",
    "            \"FileName\": os.path.basename(curr_wav_file),\n",
    "            \"Format\": \"\",         \n",
    "            \"Note\": \"\",\n",
    "            \"Take\": \"\",\n",
    "            \"Scene\": \"\",\n",
    "            \"Project\": \"\",\n",
    "            \"Category\": \"\",\n",
    "            \"Library\": \"\",\n",
    "            \"Tape\": \"\",\n",
    "            \"Channels\": \"\",\n",
    "            \"Originator\": \"\",\n",
    "            \"Reference\": \"\",\n",
    "            \"Description\": \"\",\n",
    "            \"Duration\": duration_str,\n",
    "            \"FilePath\": curr_wav_file,\n",
    "            \"Looped\": duration < 5,\n",
    "            \"vector_embedding\": embedding[i].tolist(),  \n",
    "        }\n",
    "        records_to_insert.append(metadata)\n",
    "        #fast batching for lancedb insertion & memory safe\n",
    "        if len(records_to_insert) >= batch_size_to_insert:\n",
    "            table.add(records_to_insert)\n",
    "            records_to_insert.clear()\n",
    "    # count+=1\n",
    "    # if (count>=5000):\n",
    "    #     break\n",
    "#insert any remaining records\n",
    "if records_to_insert:\n",
    "    table.add(records_to_insert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b53eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check stuff was inserted\n",
    "df = table.to_pandas()\n",
    "print(df.head())  # Show first 5 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6474d3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### STEP 3 : Generate vector embeddings of liked sounds and generate similarity search of liked sounds #######\n",
    "#loop through liked sounds & generate vector embeddings\n",
    "from IPython.display import Audio, display\n",
    "count=0\n",
    "for currLikedDict in metadata_list:\n",
    "    audio_path= currLikedDict[\"FilePath\"]\n",
    "    embedding, _= generate_embedding(audio_path)\n",
    "    for i in range(embedding.shape[0]):\n",
    "        embedding = np.array(embedding)\n",
    "        query_vector = embedding[i].tolist()\n",
    "        #search lancedb with those vector embeddings\n",
    "        results = table.search(query_vector).limit(1).to_pandas()\n",
    "        print(\"The most similar to \", audio_path, \" chunk #\", (i+1), \" is\", results[\"FilePath\"].tolist()[0])\n",
    "        print(\"Liked audio:\")\n",
    "        display(Audio(audio_path))\n",
    "        matched_path = results[\"FilePath\"].tolist()[0]\n",
    "        matched_duration = results[\"Duration\"].tolist()[0]\n",
    "        # Parse \"start-end\" from Duration field\n",
    "        start_sec, end_sec = map(int, matched_duration.split('-'))\n",
    "        duration = end_sec - start_sec\n",
    "\n",
    "        # Load just the 5-second chunk (efficient)\n",
    "        y, sr = librosa.load(matched_path, sr=None, offset=start_sec, duration=duration)\n",
    "\n",
    "        # Display the audio player\n",
    "        print(\"Most similar 5-second chunk from time :\", matched_duration)\n",
    "        display(Audio(y, rate=sr))\n",
    "\n",
    "    # count+=1\n",
    "    # if (count>5):\n",
    "    #     break\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Muha-Deliverable",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
